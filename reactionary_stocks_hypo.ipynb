{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c40941",
   "metadata": {},
   "source": [
    "# Reactions in stock prices\n",
    "\n",
    "Hypothesis Nov 16, 2022. \n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "Valuations of stock prices are an intricate network of companies offering complimentary and competitive goods. Thus, positive and negative news for one company (increasing their stock price) will lead to knock on effects for other company's stock prices.\n",
    "\n",
    "This code is dedicated to testing whether there are time delays in the price changes (percentage change) of one stock and its effect on other stocks.\n",
    "\n",
    "Disclaimer: This test will only be able to pick apart _association_, not causality. While strong patterns between stocks may emerge, I propose that rigorous testing will be necessary to confirm \n",
    "\n",
    "1. _why_ one stock may closely correlate to another,\n",
    "2. whether confirming evidence is spread uniformly throughout time (also what time frame the association is expected to be valid for),\n",
    "3. trends are not significantly defined by general macroeconomic trends.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Identifying frequently occuring instances of percent changes in the \"primary stock\" for which the \"related stock\" can be bought and sold at a profit with minimal risk.\n",
    "\n",
    "## Test setup\n",
    "\n",
    "1. Cross matching initially all S&P500 stocks with one another.\n",
    "2. Calculation of correlation coefficient between percent changes over intervals: 5m, 10m, 20m, 30m, 1h, 2h, 3h, 1d, 2d (open to revision). \n",
    "3. Prioritization of top n performers - expansion of correlation test to longer / shorter time frames.\n",
    "4. Association bootstrap test.\n",
    "__\n",
    "5. Agreement of good success parameters (provided adequate hypotheses are found). \n",
    "6. Multiple days test run to confirm validity.\n",
    "\n",
    "## Meeting Notes\n",
    "\n",
    "- Take big jumps from company - look at other big jumps from other stocks with phase shift.\n",
    "- Limit to well correlated companies? i.e. Pepsi and Coke.\n",
    "- Maybe look into smaller companies.\n",
    "- Compare sectors\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3556408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data\n",
    "import yfinance as yf\n",
    "import bs4 as bs\n",
    "import requests\n",
    "\n",
    "#Visualize Data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "#Manipulate Data\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "\n",
    "#Other\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "#Style setup\n",
    "plt.style.use('bmh')\n",
    "%matplotlib inline\n",
    "\n",
    "# Force display of all values INACTIVE\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7c5e8",
   "metadata": {},
   "source": [
    "## Essential functions\n",
    "\n",
    "1. `historical(stock, period, interval, tm_val)` - GET yFinance ticker price, data preprocessing\n",
    "2. `get_snp500()` - GET wikipedia s&p500 tickers\n",
    "3. `percent_change(val_1, val_2)` - Get percentage change between two values\n",
    "4. `standardize(arr_n)` - Standardize numerical array\n",
    "5. `offset(stock_a, stock_b, period, interval, n)` - Get r for stock_a predicting stock_b by n intervals (disclaimer: try / except clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fc9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prefix(line, fmt):\n",
    "    try:\n",
    "        t = time.strptime(line, fmt)\n",
    "    except ValueError as v:\n",
    "        if len(v.args) > 0 and v.args[0].startswith('unconverted data remains: '):\n",
    "            line = line[:-(len(v.args[0]) - 26)]\n",
    "            t = time.strptime(line, fmt)\n",
    "        else:\n",
    "            raise\n",
    "    return t\n",
    "\n",
    "def historical(stock, period, interval, tm_val):\n",
    "    #valid TM_VAL: date, time\n",
    "    # valid PERIOD: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "    # valid INTERVAL: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "    \n",
    "    #Fetch data\n",
    "    price_history = yf.download(tickers=stock, period=period, interval=interval, progress=False) # period: Smallest subdivision, interval: Time frame\n",
    "\n",
    "    time_series = list(price_history['Open'])\n",
    "    time_series_h = list(price_history['High'])\n",
    "    time_series_l = list(price_history['Low'])\n",
    "    \n",
    "    #Format time\n",
    "    dt_list = make_array()\n",
    "    \n",
    "    first_day = \"\"\n",
    "    first = 0\n",
    "    for dt in list(price_history.index):\n",
    "        if first == 0:\n",
    "            first_day = str(dt)\n",
    "        first += 1\n",
    "        if tm_val == \"date\":\n",
    "            date = parse_prefix(str(dt), '%Y-%m-%d %H:%M:%S')\n",
    "            day = \"{}-{}-{}\".format(date[0], date[1], date[2])\n",
    "            dt_list = append(dt_list, day)\n",
    "        elif tm_val == \"time\":\n",
    "            date = parse_prefix(str(dt), '%Y-%m-%d %H:%M:%S')\n",
    "            day = \"{}:{}\".format(date[3], date[4])\n",
    "            dt_list = append(dt_list, day)\n",
    "            \n",
    "    history = Table().with_columns({\"Date\": dt_list, \"Valuation\": time_series, \"High\": time_series_h, \"Low\": time_series_l})\n",
    "    \n",
    "    return first_day, history\n",
    "\n",
    "def get_snp500():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "    tickers = []\n",
    "\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "    \n",
    "    tickers = [s.replace('\\n', '') for s in tickers]\n",
    "\n",
    "    return tickers\n",
    "\n",
    "def percent_change(val_1, val_2):\n",
    "    return (val_2 - val_1) / val_1\n",
    "\n",
    "def standardize(arr_n):\n",
    "    avr_stock = average(arr_n)\n",
    "    std_stock = std(arr_n)\n",
    "    stdized_stock = (arr_n - avr_stock) / std_stock\n",
    "    return stdized_stock\n",
    "\n",
    "def stock_price_to_percent(dict_n):\n",
    "    avr_stock_a = dict_n[1].column(\"Valuation\")\n",
    "    percentage_stock_a = make_array()\n",
    "    for i in range(0, len(avr_stock_a) - 1): \n",
    "        percentage_stock_a = append(percentage_stock_a, percent_change(avr_stock_a[i], avr_stock_a[i + 1]))\n",
    "    return percentage_stock_a\n",
    "    \n",
    "def offset(stock_a, stock_b, period, interval, n):\n",
    "    \n",
    "    # Get data\n",
    "    try:\n",
    "        stock_a_hist = historical(stock_a, period, interval, \"date\")\n",
    "        stock_b_hist = historical(stock_b, period, interval, \"date\")\n",
    "\n",
    "        # Convert to percentage & standardize\n",
    "        stock_a_perc = stock_price_to_percent(stock_a_hist)\n",
    "        stock_b_perc = stock_price_to_percent(stock_b_hist)\n",
    "    \n",
    "        # Offset by n units\n",
    "        stock_a_offset = stock_a_perc[:len(stock_a_perc)-n]\n",
    "        stock_b_offset = stock_b_perc[n:]\n",
    "\n",
    "        stock_a_std = standardize(stock_a_offset)\n",
    "        stock_b_std = standardize(stock_b_offset)\n",
    "    \n",
    "        stock_compared = Table().with_columns(stock_a, stock_a_std, stock_b, stock_b_std)\n",
    "    \n",
    "        # stock_compared.scatter(stock_a)\n",
    "    \n",
    "        r = mean(stock_a_std * stock_b_std)\n",
    "        return r\n",
    "    \n",
    "    except:\n",
    "        return \"nan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf240bdd",
   "metadata": {},
   "source": [
    "### 1 Day correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74246701",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_tick = get_snp500()[0:2]\n",
    "\n",
    "def cross_correlate(stocks, interval, test_length, offset_interval):\n",
    "\n",
    "    all_correlations = Table(make_array(\"Stock\", \"Predicting\", \"r\"))\n",
    "\n",
    "    for i in tqdm(short_tick):\n",
    "        for j in short_tick:\n",
    "            all_correlations = all_correlations.with_row([i, j, offset(i, j, test_length, interval, offset_interval)])\n",
    "    return all_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e45a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correlate(short_tick, \"1d\", \"1y\", 1).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
